{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36455b76",
   "metadata": {},
   "source": [
    "# Notebook práctico para el EFT: solución con LLM+RAG, agente funcional, observabilidad, trazabilidad y seguridad.\n",
    "\n",
    "Este notebook demuestra la solución pedida en el EFT: carga de datos, RAG, agente funcional con memoria y planificación, observabilidad (precisión/latencia/consistencia), trazabilidad y protocolos de seguridad. Usa los módulos del repositorio (`agent/*`, `data/knowledge/*`, `storage/*`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ee70a",
   "metadata": {},
   "source": [
    "# 1. Importar librerías y configuración inicial\n",
    "En VS Code y Colab: configurar entorno, cargar claves desde variables de entorno, definir rutas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8248f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rutas: c:\\Users\\Javier\\Desktop\\Instituto\\IA\\EV3\\IAEva-main\\data\\knowledge c:\\Users\\Javier\\Desktop\\Instituto\\IA\\EV3\\IAEva-main\\storage\n"
     ]
    }
   ],
   "source": [
    "# Código: configuración mínima\n",
    "import os, time, json, pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = pathlib.Path(r\"c:/Users/Javier/Desktop/Instituto/IA/EV3/IAEva-main\")\n",
    "DATA_DIR = ROOT / \"data\" / \"knowledge\"\n",
    "STORAGE_DIR = ROOT / \"storage\"\n",
    "LOGS_FILE = STORAGE_DIR / \"logs\" / \"interactions.jsonl\"\n",
    "NOTES_FILE = STORAGE_DIR / \"notes.json\"\n",
    "CHROMA_DIR = STORAGE_DIR / \"chroma\"\n",
    "\n",
    "os.environ.setdefault(\"LLM_API_KEY\", os.getenv(\"LLM_API_KEY\", \"demo-key\"))\n",
    "print(\"Rutas:\", DATA_DIR, STORAGE_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ff1e6",
   "metadata": {},
   "source": [
    "# 2. Cargar y preprocesar datos internos/externos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "894e68a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos cargados: 2\n",
      "Ejemplo fuente: politicas.md\n"
     ]
    }
   ],
   "source": [
    "# Código: lectura simple de conocimiento interno\n",
    "from pathlib import Path\n",
    "\n",
    "files = list(DATA_DIR.glob(\"*.md\"))\n",
    "docs = []\n",
    "for f in files:\n",
    "    text = f.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    docs.append({\"path\": str(f), \"text\": text, \"meta\": {\"source\": f.name, \"date\": datetime.now().isoformat()}})\n",
    "\n",
    "print(f\"Documentos cargados: {len(docs)}\")\n",
    "print(\"Ejemplo fuente:\", docs[0][\"meta\"][\"source\"] if docs else \"sin documentos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84765bed",
   "metadata": {},
   "source": [
    "# 3. Construir vector store y pipeline RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17517850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks recuperados: 2 | Latencia: 0.1 ms\n",
      "1 politicas.md\n",
      "2 procedimientos.md\n"
     ]
    }
   ],
   "source": [
    "# Código: RAG mínimo con placeholders\n",
    "# Nota: se usa un retriever simplificado (busca por palabras clave)\n",
    "\n",
    "def simple_retriever(query, docs, k=3):\n",
    "    q = query.lower().split()\n",
    "    scored = []\n",
    "    for d in docs:\n",
    "        score = sum(word in d[\"text\"].lower() for word in q)\n",
    "        if score:\n",
    "            scored.append((score, d))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [d for _, d in scored[:k]]\n",
    "\n",
    "query = \"protocolos de seguridad y uso responsable\"\n",
    "start = time.time()\n",
    "retrieved = simple_retriever(query, docs, k=3)\n",
    "latency_ms = (time.time() - start) * 1000\n",
    "print(f\"Chunks recuperados: {len(retrieved)} | Latencia: {latency_ms:.1f} ms\")\n",
    "for i, r in enumerate(retrieved, 1):\n",
    "    print(i, r[\"meta\"][\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa97c2",
   "metadata": {},
   "source": [
    "# 4. Ingeniería de prompts y plantillas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "916219d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"analista\",\n",
      "  \"task\": \"Responder con citas y políticas aplicables\",\n",
      "  \"format\": {\n",
      "    \"answer\": \"string\",\n",
      "    \"citations\": [\n",
      "      {\n",
      "        \"source\": \"string\",\n",
      "        \"snippet\": \"string\"\n",
      "      }\n",
      "    ],\n",
      "    \"confidence\": \"0-1\"\n",
      "  },\n",
      "  \"constraints\": [\n",
      "    \"No inventar citas\",\n",
      "    \"Respetar privacidad\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Código: plantilla de prompt (JSON) para respuestas citadas\n",
    "import textwrap\n",
    "\n",
    "prompt_template = {\n",
    "    \"role\": \"analista\",\n",
    "    \"task\": \"Responder con citas y políticas aplicables\",\n",
    "    \"format\": {\n",
    "        \"answer\": \"string\",\n",
    "        \"citations\": [{\"source\": \"string\", \"snippet\": \"string\"}],\n",
    "        \"confidence\": \"0-1\"\n",
    "    },\n",
    "    \"constraints\": [\"No inventar citas\", \"Respetar privacidad\"],\n",
    "}\n",
    "print(json.dumps(prompt_template, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c0617",
   "metadata": {},
   "source": [
    "# 5. Orquestación del LLM con control de contexto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b55b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"Respuesta sobre: protocolos de seguridad y uso responsable. Basada en 2 fuentes.\",\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"source\": \"politicas.md\",\n",
      "      \"snippet\": \"# Políticas de Comunicación Interna\\n- Toda comunicación externa debe pasar por el área de Comunicaciones.\\n- Los reportes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"procedimientos.md\",\n",
      "      \"snippet\": \"# Procedimiento de Onboarding\\n1. Crear cuenta institucional.\\n2. Asignar rutas de acceso.\\n3. Revisión de políticas el pri\"\n",
      "    }\n",
      "  ],\n",
      "  \"confidence\": 0.7\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Código: simulación de llamada LLM con contexto\n",
    "# Se usa un \"LLM\" placeholder que combina plantilla + contexto recuperado.\n",
    "\n",
    "def fake_llm_answer(query, retrieved, prompt):\n",
    "    citations = [{\"source\": r[\"meta\"][\"source\"], \"snippet\": r[\"text\"][:120]} for r in retrieved]\n",
    "    answer = f\"Respuesta sobre: {query}. Basada en {len(retrieved)} fuentes.\"\n",
    "    return {\"answer\": answer, \"citations\": citations, \"confidence\": 0.7}\n",
    "\n",
    "resp = fake_llm_answer(query, retrieved, prompt_template)\n",
    "print(json.dumps(resp, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0c76d",
   "metadata": {},
   "source": [
    "# 6. Implementar agente con herramientas de consulta, escritura y razonamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7052add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutado. Latencia: 0.7 ms | Fuentes: ['politicas.md', 'procedimientos.md']\n"
     ]
    }
   ],
   "source": [
    "# Código: agente mínimo con herramientas\n",
    "\n",
    "def tool_write_note(note):\n",
    "    notes = []\n",
    "    if NOTES_FILE.exists():\n",
    "        try:\n",
    "            notes = json.loads(NOTES_FILE.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            notes = []\n",
    "    notes.append({\"ts\": datetime.now().isoformat(), \"note\": note})\n",
    "    NOTES_FILE.write_text(json.dumps(notes, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def run_agent_task(query):\n",
    "    start = time.time()\n",
    "    retrieved_local = simple_retriever(query, docs, k=3)\n",
    "    resp_local = fake_llm_answer(query, retrieved_local, prompt_template)\n",
    "    tool_write_note(f\"{resp_local['answer']} | fuentes: {[c['source'] for c in resp_local['citations']]}\")\n",
    "    duration = (time.time() - start) * 1000\n",
    "    # log\n",
    "    LOGS_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(LOGS_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps({\n",
    "            \"ts\": datetime.now().isoformat(),\n",
    "            \"query\": query,\n",
    "            \"latency_ms\": duration,\n",
    "            \"sources\": [c['source'] for c in resp_local['citations']]\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "    return {\"duration_ms\": duration, \"sources\": [c['source'] for c in resp_local['citations']]}\n",
    "\n",
    "metrics = run_agent_task(\"procedimientos y políticas de privacidad\")\n",
    "print(\"Ejecutado. Latencia:\", f\"{metrics['duration_ms']:.1f} ms\", \"| Fuentes:\", metrics[\"sources\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965dd7e",
   "metadata": {},
   "source": [
    "# 7. Memoria del agente y recuperación de contexto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb90a9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notas almacenadas: 2\n",
      "Última nota: Respuesta sobre: procedimientos y políticas de privacidad. Basada en 2 fuentes. | fuentes: ['politicas.md', 'procedimientos.md']\n"
     ]
    }
   ],
   "source": [
    "# Código: recuperación de notas previas (memoria persistente)\n",
    "if NOTES_FILE.exists():\n",
    "    notes = json.loads(NOTES_FILE.read_text(encoding=\"utf-8\"))\n",
    "    print(f\"Notas almacenadas: {len(notes)}\")\n",
    "    print(\"Última nota:\", notes[-1][\"note\"] if notes else \"sin notas\")\n",
    "else:\n",
    "    print(\"No hay notas aún.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4b2d2",
   "metadata": {},
   "source": [
    "# 8. Planificación y toma de decisiones del agente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ab6a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'step': 1, 'action': 'recuperar'}, {'step': 2, 'action': 'razonar'}, {'step': 3, 'action': 'escribir_nota'}]\n"
     ]
    }
   ],
   "source": [
    "# Código: planner sencillo (descomposición de tarea)\n",
    "\n",
    "def simple_planner(goal):\n",
    "    return [\n",
    "        {\"step\": 1, \"action\": \"recuperar\"},\n",
    "        {\"step\": 2, \"action\": \"razonar\"},\n",
    "        {\"step\": 3, \"action\": \"escribir_nota\"},\n",
    "    ]\n",
    "\n",
    "plan = simple_planner(\"Generar reporte de políticas de seguridad\")\n",
    "print(plan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7145d901",
   "metadata": {},
   "source": [
    "# 9. Observabilidad: precisión, latencia y consistencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39296ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.3333333333333333, 'latency_p95_ms': 90208.7, 'latency_var': 819499290.5}\n"
     ]
    }
   ],
   "source": [
    "# Código: métricas simples\n",
    "import statistics\n",
    "\n",
    "# precisión (proxy): coincidencia de palabras clave en respuesta\n",
    "keywords = [\"seguridad\", \"privacidad\", \"políticas\"]\n",
    "precision = sum(k in resp[\"answer\"].lower() for k in keywords) / len(keywords)\n",
    "\n",
    "# latencia: medimos de logs p95\n",
    "latencies = []\n",
    "if LOGS_FILE.exists():\n",
    "    with open(LOGS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                latencies.append(json.loads(line)[\"latency_ms\"])\n",
    "            except Exception:\n",
    "                pass\n",
    "p95 = statistics.quantiles(latencies, n=20)[18] if len(latencies) >= 20 else (max(latencies) if latencies else 0)\n",
    "\n",
    "# consistencia: estabilidad entre runs (proxy: varianza de latencias)\n",
    "variance = statistics.pvariance(latencies) if len(latencies) > 1 else 0\n",
    "\n",
    "metrics_summary = {\"precision\": precision, \"latency_p95_ms\": round(p95,1), \"latency_var\": round(variance,1)}\n",
    "print(metrics_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e89db",
   "metadata": {},
   "source": [
    "# 10. Trazabilidad: logging estructurado y análisis de registros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ff26e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros: 8\n",
      "{'ts': '2025-11-30T18:56:29.138179', 'query': 'procedimientos y políticas de privacidad', 'latency_ms': 0.5888938903808594, 'sources': ['politicas.md', 'procedimientos.md']}\n"
     ]
    }
   ],
   "source": [
    "# Código: lectura y resumen de trazas\n",
    "traces = []\n",
    "if LOGS_FILE.exists():\n",
    "    with open(LOGS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                traces.append(json.loads(line))\n",
    "            except Exception:\n",
    "                pass\n",
    "print(f\"Registros: {len(traces)}\")\n",
    "print(traces[-1] if traces else \"sin registros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57844b2",
   "metadata": {},
   "source": [
    "# 11. Protocolos de seguridad, privacidad y uso responsable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2820df94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pii': False, 'toxic': False}\n"
     ]
    }
   ],
   "source": [
    "# Código: validación simple de salida (no PII, no toxicidad)\n",
    "\n",
    "def validate_output(resp):\n",
    "    text = resp[\"answer\"].lower()\n",
    "    flags = {\n",
    "        \"pii\": any(x in text for x in [\"rut\", \"dni\", \"telefono\", \"email\"]),\n",
    "        \"toxic\": any(x in text for x in [\"odio\", \"insulto\"]),\n",
    "    }\n",
    "    return flags\n",
    "\n",
    "print(validate_output(resp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b24792",
   "metadata": {},
   "source": [
    "# 12. Propuestas de mejora basadas en métricas y registros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "605cd492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Agregar caché y reducir k en el retriever', 'Ajustar prompts y mejorar verificación de citas', 'Instrumentar métricas adicionales en dashboard']\n"
     ]
    }
   ],
   "source": [
    "# Código: recomendaciones (placeholder)\n",
    "\n",
    "def recommend_changes(metrics, traces):\n",
    "    recs = []\n",
    "    if metrics.get(\"latency_p95_ms\", 0) > 500:\n",
    "        recs.append(\"Agregar caché y reducir k en el retriever\")\n",
    "    if metrics.get(\"precision\", 0) < 0.5:\n",
    "        recs.append(\"Ajustar prompts y mejorar verificación de citas\")\n",
    "    recs.append(\"Instrumentar métricas adicionales en dashboard\")\n",
    "    return recs\n",
    "\n",
    "print(recommend_changes(metrics_summary, traces))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
